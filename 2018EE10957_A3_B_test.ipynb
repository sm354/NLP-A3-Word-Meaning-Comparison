{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2018EE10957_A3_B_test.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSkHozvq7gGh"
      },
      "source": [
        "Make a copy of this notebook and rename using your USERID in the following format, 2017CSZ8058\n",
        "\n",
        "Give editor access to keshavkolluru@gmail.com, vishalsaley114@gmail.com and kartikeya.badola@gmail.com\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPmKrdbC48JU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36284c62-2dbd-40f6-8222-249d9cc3b658"
      },
      "source": [
        "## DONT CHANGE THIS CELL \n",
        "# this is currently the same as dev.data.txt\n",
        "!wget http://www.cse.iitd.ac.in/~mausam/courses/col772/autumn2021/A3/test.data.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-11 15:22:54--  http://www.cse.iitd.ac.in/~mausam/courses/col772/autumn2021/A3/test.data.txt\n",
            "Resolving www.cse.iitd.ac.in (www.cse.iitd.ac.in)... 103.27.9.152\n",
            "Connecting to www.cse.iitd.ac.in (www.cse.iitd.ac.in)|103.27.9.152|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://www.cse.iitd.ac.in/~mausam/courses/col772/autumn2021/A3/test.data.txt [following]\n",
            "--2021-10-11 15:22:55--  https://www.cse.iitd.ac.in/~mausam/courses/col772/autumn2021/A3/test.data.txt\n",
            "Connecting to www.cse.iitd.ac.in (www.cse.iitd.ac.in)|103.27.9.152|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 63639 (62K) [text/plain]\n",
            "Saving to: ‘test.data.txt’\n",
            "\n",
            "test.data.txt       100%[===================>]  62.15K  84.3KB/s    in 0.7s    \n",
            "\n",
            "2021-10-11 15:22:57 (84.3 KB/s) - ‘test.data.txt’ saved [63639/63639]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJv-12oi_zKg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1e38bdf-f776-4459-f9e9-36d0a4aa44f5"
      },
      "source": [
        "## Replace with the right link that contains the zip file uploaded from the training\n",
        "!gdown https://drive.google.com/uc?id=14Ij4NX-AWXULDxs0dNM3K8apTB8OCnX9"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=14Ij4NX-AWXULDxs0dNM3K8apTB8OCnX9\n",
            "To: /content/2018EE10957_A_model.zip\n",
            "100% 16.7M/16.7M [00:00<00:00, 63.0MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BbuJGhU30TxS",
        "outputId": "449e8029-85aa-4e53-806a-bf711cc3ca48"
      },
      "source": [
        "!unzip 2018EE10957_A_model.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  2018EE10957_A_model.zip\n",
            "   creating: 2018EE10957_A_model/\n",
            "  inflating: 2018EE10957_A_model/best-biLSTM-params.pt  \n",
            "  inflating: 2018EE10957_A_model/Field_TEXT  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Sh-Mw6cAIcH"
      },
      "source": [
        "import os\n",
        "import pandas\n",
        "import numpy as np\n",
        "import dill\n",
        "import torch\n",
        "import torch.optim as O\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from torchtext.legacy import data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kgv8lgF9UWbd"
      },
      "source": [
        "## Various utility functions\n",
        "\n",
        "class args_class:\n",
        "    dataset = \"data/\"\n",
        "    model = \"biLSTM\"\n",
        "    gpu = 0\n",
        "    batch_size = 32\n",
        "    epochs = 20\n",
        "    hidden_dim = 64\n",
        "    lr = 0.001"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVodp0iKUWX8"
      },
      "source": [
        "def parse_args():\n",
        "\t# parser = ArgumentParser(description='NLI Baseline')\n",
        "\t# parser.add_argument('--dataset', '-d', type=str, default='mnli')\n",
        "\t# parser.add_argument('--model', '-m', type=str, default='bilstm')\n",
        "\t# parser.add_argument('--gpu', type=int, default=0)\n",
        "\t# parser.add_argument('--batch_size', type=int, default=128)\n",
        "\t# parser.add_argument('--embed_dim', type=int, default=300)\n",
        "\t# parser.add_argument('--d_hidden', type=int, default=200)\n",
        "\t# parser.add_argument('--dp_ratio', type=int, default=0.2)\n",
        "\t# parser.add_argument('--epochs', type=int, default=20)\n",
        "\t# parser.add_argument('--lr', type=float, default=0.001)\n",
        "\t# parser.add_argument('--combine', type=str, default='cat')\n",
        "\t# parser.add_argument('--results_dir', type=str, default='results')\n",
        "\targs = args_class()\n",
        "\treturn check_args(args)\n",
        "\n",
        "\"\"\"checking arguments\"\"\"\n",
        "def check_args(args):\n",
        "\t# --result_dir\n",
        "\tcheck_folder(os.path.join(args.dataset))\n",
        "\n",
        "\t# --epoch\n",
        "\ttry:\n",
        "\t\t\tassert args.epochs >= 1\n",
        "\texcept:\n",
        "\t\t\tprint('number of epochs must be larger than or equal to one')\n",
        "\n",
        "\t# --batch_size\n",
        "\ttry:\n",
        "\t\t\tassert args.batch_size >= 1\n",
        "\texcept:\n",
        "\t\t\tprint('batch size must be larger than or equal to one')\n",
        "\treturn args\n",
        "\n",
        "def get_device(gpu_no):\n",
        "\tif torch.cuda.is_available():\n",
        "\t\ttorch.cuda.set_device(gpu_no)\n",
        "\t\treturn torch.device('cuda:{}'.format(gpu_no))\n",
        "\telse:\n",
        "\t\treturn torch.device('cpu')\n",
        "\n",
        "def makedirs(name):\n",
        "\t\"\"\"helper function for python 2 and 3 to call os.makedirs()\n",
        "\t\tavoiding an error if the directory to be created already exists\"\"\"\n",
        "\n",
        "\timport os, errno\n",
        "\n",
        "\ttry:\n",
        "\t\tos.makedirs(name)\n",
        "\texcept OSError as ex:\n",
        "\t\tif ex.errno == errno.EEXIST and os.path.isdir(name):\n",
        "\t\t\t# ignore existing directory\n",
        "\t\t\tpass\n",
        "\t\telse:\n",
        "\t\t\t# a different error happened\n",
        "\t\t\traise\n",
        "\n",
        "def check_folder(log_dir):\n",
        "\tif not os.path.exists(log_dir):\n",
        "\t\tos.makedirs(log_dir)\n",
        "\treturn log_dir\n",
        "\n",
        "def get_logger(args, phase):\n",
        "\tlogging.basicConfig(level=logging.INFO, \n",
        "\t\t\t\t\t\t\t\t\t\t\t\tfilename = \"{}/{}_{}.log\".format(args.dataset, args.model, phase),\n",
        "\t\t\t\t\t\t\t\t\t\t\t\tformat = '%(asctime)s - %(message)s', \n",
        "\t\t\t\t\t\t\t\t\t\t\t\tdatefmt='%d-%b-%y %H:%M:%S')\n",
        "\treturn logging.getLogger(phase)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jDu7f3pUWOf"
      },
      "source": [
        "class myModel(nn.Module):\n",
        "    def __init__(self, pretrained_embeddings, embed_dim=100, hidden_dim=100, device=torch.device('cpu')):\n",
        "        super(myModel, self).__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.device = device\n",
        "        \n",
        "        self.embedding = nn.Embedding.from_pretrained(pretrained_embeddings, freeze=True)\n",
        "        # self.dropout = nn.Dropout(p = 0.5)\n",
        "        self.bilstm = nn.LSTM(embed_dim, hidden_dim, bidirectional=False, batch_first=True, num_layers=2)\n",
        "        # self.fc = nn.Linear(hidden_dim, 2)\n",
        "        # self.attn = nn.MultiheadAttention(embed_dim=300, num_heads=4, batch_first=True) #self.hidden_dim\n",
        "        self.similarity = nn.CosineSimilarity(dim=1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, input):\n",
        "        '''\n",
        "            [torchtext.legacy.data.batch.Batch of size 32]\n",
        "                [.word]:[torch.LongTensor of size 1x32]\n",
        "                [.POS]:[torch.LongTensor of size 32]\n",
        "                [.sen1]:[torch.LongTensor of size 17x32]\n",
        "                [.word1]:[torch.LongTensor of size 32]\n",
        "                [.sen2]:[torch.LongTensor of size 26x32]\n",
        "                [.word2]:[torch.LongTensor of size 32]\n",
        "                [.label]:[torch.LongTensor of size 32]\n",
        "        '''\n",
        "        input1 = input.sen1.permute(1,0).to(self.device)\n",
        "        input2 = input.sen2.permute(1,0).to(self.device)\n",
        "\n",
        "        # embed the tokens (indices in the vocab) \n",
        "        # out1 = self.dropout(self.embedding(input1))\n",
        "        # out2 = self.dropout(self.embedding(input2))\n",
        "        out1 = self.embedding(input1)\n",
        "        out2 = self.embedding(input2)\n",
        "        \n",
        "        out1, (_, _) = self.bilstm(out1)\n",
        "        out2, (_, _) = self.bilstm(out2)\n",
        "        \n",
        "        # mask1 = (input1 == 1)\n",
        "        # mask2 = (input2 == 1)\n",
        "\n",
        "        # attention box\n",
        "        # (out1, _) = self.attn(out1, out1, out1, key_padding_mask=mask1)\n",
        "        # (out2, _) = self.attn(out2, out2, out2, key_padding_mask=mask2)\n",
        "        \n",
        "        # word of interest\n",
        "        woi1_idx = torch.repeat_interleave(torch.unsqueeze(torch.unsqueeze(input.word1, 1), 2), self.hidden_dim, dim=2).to(self.device)\n",
        "        woi2_idx = torch.repeat_interleave(torch.unsqueeze(torch.unsqueeze(input.word2, 1), 2), self.hidden_dim, dim=2).to(self.device)\n",
        "        \n",
        "        # gather the word of interest for each sentence in the batch\n",
        "        out1 = torch.gather(input=out1, dim=1, index=woi1_idx).squeeze()\n",
        "        out2 = torch.gather(input=out2, dim=1, index=woi2_idx).squeeze()\n",
        "        \n",
        "        # linear layer\n",
        "        #out1 = self.fc(out1)\n",
        "        #out2 = self.fc(out2)\n",
        "        \n",
        "        # compute scores of similarity\n",
        "        out = self.similarity(out1, out2)\n",
        "        out = self.sigmoid(out)\n",
        "        # try:\n",
        "        #     assert out.shape[0] == self.bs\n",
        "        # except:\n",
        "        #     print(\"AssertionError\", out.shape[0], self.bs) # all samples are touched in a epoch\n",
        "\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJ_sQw68UhsZ"
      },
      "source": [
        "import spacy\n",
        "en = spacy.load('en_core_web_sm')\n",
        "def tokeni(sen):\n",
        "    t = en.tokenizer(sen)\n",
        "    return [word.text for word in t]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37ln6VDqUhm9"
      },
      "source": [
        "def main():\n",
        "    hidden_dim=64\n",
        "    device = get_device(0)\n",
        "\n",
        "    x_test = pandas.read_csv(\"test.data.txt\", delimiter='\\t', header=None, names=['word', 'POS', 'position', 'sen1', 'sen2'])\n",
        "    word1 = x_test.loc[:,'position'].apply(lambda positions : positions.split(\"-\")[0])\n",
        "    word2 = x_test.loc[:,'position'].apply(lambda positions : positions.split(\"-\")[1])\n",
        "    x_test = x_test.drop(\"position\", axis=1)\n",
        "    x_test.loc[:, \"POS\"] = x_test.loc[:, \"POS\"].apply(lambda POS_TAG : 0 if POS_TAG==\"V\" else 1)\n",
        "    x_test.insert(3, \"word1\", word1)\n",
        "    x_test.insert(5, \"word2\", word2)\n",
        "    x_test.to_csv(\"./test.csv\", header=None, index=False)\n",
        "\n",
        "    with open(os.path.join(\"2018EE10957_A_model\", \"Field_TEXT\"), 'rb') as f:\n",
        "        TEXT = dill.load(f)\n",
        "\n",
        "    fields = [\n",
        "        ('word', TEXT),\n",
        "        ('POS', data.Field(use_vocab=False, sequential=False)), \n",
        "        ('sen1', TEXT),\n",
        "        ('word1', data.Field(use_vocab=False, sequential=False)),\n",
        "        ('sen2', TEXT),\n",
        "        ('word2', data.Field(use_vocab=False, sequential=False)),\n",
        "    ]\n",
        "\n",
        "    test_set = data.TabularDataset(\n",
        "        path = \"./test.csv\",\n",
        "        format = 'csv',\n",
        "        fields = fields,\n",
        "        skip_header = False\n",
        "    )\n",
        "\n",
        "    test_itr = data.BucketIterator(\n",
        "        test_set,\n",
        "        #sort_key = lambda sample : len(sample.sen1),\n",
        "        sort = False,\n",
        "        batch_size = 32,\n",
        "        repeat = False,\n",
        "        shuffle = False,\n",
        "    )\n",
        "\n",
        "    model = myModel(pretrained_embeddings=TEXT.vocab.vectors, embed_dim=TEXT.vocab.vectors.shape[1], hidden_dim=hidden_dim, device=device)\n",
        "    saved_model = torch.load(\"2018EE10957_A_model/best-biLSTM-params.pt\", map_location=device)\n",
        "    print(saved_model[\"accuracy\"])\n",
        "    model.load_state_dict(saved_model['model_dict'])\n",
        "    model = model.to(device)\n",
        "\n",
        "    model.eval()\n",
        "    test_itr.init_epoch()\n",
        "    predictions = []\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, batch in enumerate(test_itr):\n",
        "            answer = model(batch)\n",
        "            answer = list(np.array((answer>=0.5).long().cpu()))\n",
        "            predictions += answer\n",
        "\n",
        "    predictions = pandas.DataFrame(predictions)[0].apply(lambda label : \"T\" if label == 1 else \"F\")\n",
        "    predictions.to_csv(\"output.txt\", header=None, index=None)\n",
        "    print(\"predictions written in output.txt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5WS4GJ_Uhgq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5fd1305-6d38-4fbe-9b55-d28f42cee666"
      },
      "source": [
        "main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63.47962382445141\n",
            "predictions written in output.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-IlAUkv7s1C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "411694ab-3720-4734-ca4d-f10ac8afecdc"
      },
      "source": [
        "## DONT CHANGE THIS CELL\n",
        "# Your testing code must produce a file output.txt with predictions as T and F in each line\n",
        "\n",
        "## Final Evaluation \n",
        "# this is currently the same as dev.gold.txt\n",
        "!wget http://www.cse.iitd.ac.in/~mausam/courses/col772/autumn2021/A3/test.gold.txt\n",
        "correct, total = 0., 0.\n",
        "for prediction, gold in zip(open('output.txt'), open('test.gold.txt')):\n",
        "  prediction, gold = prediction.strip(), gold.strip()\n",
        "  total += 1\n",
        "  if prediction == gold:\n",
        "    correct += 1\n",
        "\n",
        "## Report this as the final validation performance \n",
        "print('Performance = ', (correct/total))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-11 15:25:03--  http://www.cse.iitd.ac.in/~mausam/courses/col772/autumn2021/A3/test.gold.txt\n",
            "Resolving www.cse.iitd.ac.in (www.cse.iitd.ac.in)... 103.27.9.152\n",
            "Connecting to www.cse.iitd.ac.in (www.cse.iitd.ac.in)|103.27.9.152|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://www.cse.iitd.ac.in/~mausam/courses/col772/autumn2021/A3/test.gold.txt [following]\n",
            "--2021-10-11 15:25:04--  https://www.cse.iitd.ac.in/~mausam/courses/col772/autumn2021/A3/test.gold.txt\n",
            "Connecting to www.cse.iitd.ac.in (www.cse.iitd.ac.in)|103.27.9.152|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1276 (1.2K) [text/plain]\n",
            "Saving to: ‘test.gold.txt’\n",
            "\n",
            "test.gold.txt       100%[===================>]   1.25K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-10-11 15:25:05 (46.8 MB/s) - ‘test.gold.txt’ saved [1276/1276]\n",
            "\n",
            "Performance =  0.6347962382445141\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KmCASY_9LaQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}