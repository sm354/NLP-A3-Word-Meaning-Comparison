{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FWjwfx8T5OAJ"
   },
   "source": [
    "Make a copy of this notebook and rename using your USERID in the following format, 2017CSZ8058\n",
    "\n",
    "Give read access to keshavkolluru@gmail.com, vishalsaley114@gmail.com and kartikeya.badola@gmail.com\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "spAvH1fF0Rhg"
   },
   "outputs": [],
   "source": [
    "# ## DONT CHANGE THIS CELL\n",
    "# !wget http://www.cse.iitd.ac.in/~mausam/courses/col772/autumn2021/A3/data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "LrnkLN2LzlDB"
   },
   "outputs": [],
   "source": [
    "## Import relevant packages\n",
    "\n",
    "import os\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "import torch\n",
    "import torch.optim as O\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "import logging\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "from pdb import set_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sr3ok6g51O_d"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "14EjR4tmz2x5"
   },
   "outputs": [],
   "source": [
    "## Basic training loop\n",
    "\n",
    "class Train():\n",
    "    def __init__(self):\n",
    "#         print(\"program execution start: {}\".format(datetime.datetime.now()))\n",
    "#         self.args = parse_args()\n",
    "#         self.device = get_device(self.args.gpu)\n",
    "#         self.logger = get_logger(self.args, \"train\")\n",
    "#         self.logger.info(\"Arguments: {}\".format(self.args))\n",
    "\n",
    "#         dataset_options = {\n",
    "#                                             'batch_size': self.args.batch_size, \n",
    "#                                             'device': self.device\n",
    "#                                         }\n",
    "\n",
    "    ## TODO: Load your own dataset\n",
    "        self.dataset = None\n",
    "\n",
    "    ## TODO: Load your own model\n",
    "        self.model = None\n",
    "\n",
    "        self.model.to(self.device)\n",
    "        self.criterion = nn.CrossEntropyLoss(reduction = 'sum')\n",
    "        self.opt = O.Adam(self.model.parameters(), lr = self.args.lr)\n",
    "        self.best_val_acc = None\n",
    "        self.scheduler = StepLR(self.opt, step_size=5, gamma=0.5)\n",
    "\n",
    "        print(\"resource preparation done: {}\".format(datetime.datetime.now()))\n",
    "\n",
    "    def result_checkpoint(self, epoch, train_loss, val_loss, train_acc, val_acc, took):\n",
    "        if self.best_val_acc is None or val_acc > self.best_val_acc:\n",
    "            self.best_val_acc = val_acc\n",
    "            torch.save({\n",
    "                'accuracy': self.best_val_acc,\n",
    "                'options': self.model_options,\n",
    "                'model_dict': self.model.state_dict(),\n",
    "            }, '{}/{}/{}/best-{}-{}-params.pt'.format(self.args.results_dir, self.args.model, self.args.dataset, self.args.model, self.args.dataset))\n",
    "        self.logger.info('| Epoch {:3d} | train loss {:5.2f} | train acc {:5.2f} | val loss {:5.2f} | val acc {:5.2f} | time: {:5.2f}s |'\n",
    "                .format(epoch, train_loss, train_acc, val_loss, val_acc, took))\n",
    "\n",
    "    def train(self):\n",
    "        self.model.train(); self.dataset.train_iter.init_epoch()\n",
    "        n_correct, n_total, n_loss = 0, 0, 0\n",
    "        for batch_idx, batch in enumerate(self.dataset.train_iter):\n",
    "            self.opt.zero_grad()\n",
    "            answer = self.model(batch)\n",
    "            loss = self.criterion(answer, batch.label)\n",
    "\n",
    "            n_correct += (torch.max(answer, 1)[1].view(batch.label.size()) == batch.label).sum().item()\n",
    "            n_total += batch.batch_size\n",
    "            n_loss += loss.item()\n",
    "\n",
    "            loss.backward(); self.opt.step()\n",
    "        train_loss = n_loss/n_total\n",
    "        train_acc = 100. * n_correct/n_total\n",
    "        return train_loss, train_acc\n",
    "\n",
    "    def validate(self):\n",
    "        self.model.eval(); self.dataset.dev_iter.init_epoch()\n",
    "        n_correct, n_total, n_loss = 0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, batch in enumerate(self.dataset.dev_iter):\n",
    "                answer = self.model(batch)\n",
    "                loss = self.criterion(answer, batch.label)\n",
    "\n",
    "                n_correct += (torch.max(answer, 1)[1].view(batch.label.size()) == batch.label).sum().item()\n",
    "                n_total += batch.batch_size\n",
    "                n_loss += loss.item()\n",
    "\n",
    "            val_loss = n_loss/n_total\n",
    "            val_acc = 100. * n_correct/n_total\n",
    "            return val_loss, val_acc\n",
    "\n",
    "    def execute(self):\n",
    "        print(\" [*] Training starts!\")\n",
    "        print('-' * 99)\n",
    "        for epoch in range(1, self.args.epochs+1):\n",
    "            start = time.time()\n",
    "\n",
    "            train_loss, train_acc = self.train()\n",
    "            val_loss, val_acc = self.validate()\n",
    "            self.scheduler.step()\n",
    "\n",
    "            took = time.time()-start\n",
    "            self.result_checkpoint(epoch, train_loss, val_loss, train_acc, val_acc, took)\n",
    "\n",
    "            print('| Epoch {:3d} | train loss {:5.2f} | train acc {:5.2f} | val loss {:5.2f} | val acc {:5.2f} | time: {:5.2f}s |'.format(\n",
    "                epoch, train_loss, train_acc, val_loss, val_acc, took))\n",
    "        self.finish()\n",
    "\n",
    "    def finish(self):\n",
    "        self.logger.info(\"[*] Training finished!\\n\\n\")\n",
    "        print('-' * 99)\n",
    "        print(\" [*] Training finished!\")\n",
    "        print(\" [*] Please find the saved model and training log in results_dir\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dM2QDq2iz-h7"
   },
   "outputs": [],
   "source": [
    "## Start training\n",
    "task = Train()\n",
    "task.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G-j7z1e6OjGO"
   },
   "outputs": [],
   "source": [
    "## Zip the final model and all the required files, such as vocabulary\n",
    "# Replace USERID with your own, such as 2017CSZ8058\n",
    "!zip -r USERID_A_model.zip **\n",
    "\n",
    "## Upload it to Google drive and ensure that the testing notebook uses the correct link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Various utility functions\n",
    "def parse_args():\n",
    "    parser = ArgumentParser(description='NLI Baseline')\n",
    "    parser.add_argument('--dataset', '-d', type=str, default='mnli')\n",
    "    parser.add_argument('--model', '-m', type=str, default='bilstm')\n",
    "    parser.add_argument('--gpu', type=int, default=0)\n",
    "    parser.add_argument('--batch_size', type=int, default=128)\n",
    "    parser.add_argument('--embed_dim', type=int, default=300)\n",
    "    parser.add_argument('--d_hidden', type=int, default=200)\n",
    "    parser.add_argument('--dp_ratio', type=int, default=0.2)\n",
    "    parser.add_argument('--epochs', type=int, default=20)\n",
    "    parser.add_argument('--lr', type=float, default=0.001)\n",
    "    parser.add_argument('--combine', type=str, default='cat')\n",
    "    parser.add_argument('--results_dir', type=str, default='results')\n",
    "    return check_args(parser.parse_args())\n",
    "\n",
    "\"\"\"checking arguments\"\"\"\n",
    "def check_args(args):\n",
    "    # --result_dir\n",
    "    check_folder(os.path.join(args.results_dir, args.model, args.dataset))\n",
    "\n",
    "    # --epoch\n",
    "    try:\n",
    "        assert args.epochs >= 1\n",
    "    except:\n",
    "        print('number of epochs must be larger than or equal to one')\n",
    "\n",
    "    # --batch_size\n",
    "    try:\n",
    "        assert args.batch_size >= 1\n",
    "    except:\n",
    "        print('batch size must be larger than or equal to one')\n",
    "    return args\n",
    "\n",
    "def get_device(gpu_no):\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.set_device(gpu_no)\n",
    "        return torch.device('cuda:{}'.format(gpu_no))\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "\n",
    "def makedirs(name):\n",
    "    \"\"\"helper function for python 2 and 3 to call os.makedirs()\n",
    "        avoiding an error if the directory to be created already exists\"\"\"\n",
    "\n",
    "    import os, errno\n",
    "\n",
    "    try:\n",
    "        os.makedirs(name)\n",
    "    except OSError as ex:\n",
    "        if ex.errno == errno.EEXIST and os.path.isdir(name):\n",
    "            # ignore existing directory\n",
    "            pass\n",
    "        else:\n",
    "            # a different error happened\n",
    "            raise\n",
    "            \n",
    "def check_folder(log_dir):\n",
    "    if not os.path.exists(log_dir):\n",
    "        os.makedirs(log_dir)\n",
    "    return log_dir\n",
    "\n",
    "def get_logger(args, phase):\n",
    "    logging.basicConfig(level=logging.INFO, \n",
    "                        filename = \"{}/{}/{}/{}.log\".format(args.results_dir, args.model, args.dataset, phase),\n",
    "                        format = '%(asctime)s - %(message)s', \n",
    "                        datefmt='%d-%b-%y %H:%M:%S')\n",
    "    return logging.getLogger(phase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "2018EE10957_A3_A_train.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
